#!/usr/bin/env python
#
# This tool will take a iceshelf backup and restore it to a
# designated folder, following any directives stored in the
# manifest file.
#
# NOTE! Will not do anything if a manifest is missing.
#
##############################################################################

import logging
import argparse
import sys
import os.path
import json
from datetime import datetime
import time
import shutil
import tarfile
import gnupg
import re
from subprocess import Popen, PIPE

import modules.configuration as configuration
import modules.fileutils as fileutils
import modules.helper as helper

def validArchive(baseDir, filelist, corruptFiles, files):
  """
  Start with validating all files and confirm existance of files, using the filelist.txt
  """
  p = re.compile('([a-f0-9]+)\s+([^\s]+)')
  criticalerror = False
  archivecorrupt = False
  paritycount = 0
  del files[:]
  with open( os.path.join(baseDir, filelist), "r") as f:
    for line in f:
      res = p.match(line)
      if res:
        if os.path.exists(os.path.join(baseDir, res.group(2))):
          files.append(res.group(2))
          sha = fileutils.hashFile(os.path.join(baseDir, res.group(2)), 'sha1')
          if sha != res.group(1):
            corruptFiles.append(res.group(2))
            if ".json" in line:
              logging.error('Manifest is corrupt, please restore manually')
              criticalerror = True
            elif ".tar" in line:
              archivecorrupt = True
            elif ".par2" in line:
              logging.warn('Parity file "%s" is corrupt and will not be used' % res.group(2))
          elif ".par2" in line:
            paritycount += 1
        else:
          logging.error('File "%s" is missing from backup' % res.group(2))
          return False
      else:
        logging.error("filelist.txt is corrupt")
        return False
  if archivecorrupt and paritycount == 0:
    logging.error('Archive is corrupt and no available parity files')
    criticalerror = True
  elif archivecorrupt:
    logging.warn('Archive is corrupt, but parity is available making repair a possibility')
  return criticalerror == False

def validateFile(filename):
  global config
  gpg = gnupg.GPG()
  destfile = filename

  logging.debug('Validating "%s"' % filename)

  if filename.endswith('.sig') or filename.endswith('.asc'):
    verification = None
    with open(filename, 'rb') as f:
      verification = gpg.verify_file(f)
    if verification is None or verification.trust_level < verification.TRUST_FULLY:
      logging.error('Signature isn\'t trusted (%s): %s' % (verification.status, filename))
      return False
  return True

def stripFile(filename):
  global config
  gpg = gnupg.GPG()
  destfile = filename

  logging.debug('Processing "%s"' % filename)

  while destfile.endswith('.sig') or destfile.endswith('.asc') or destfile.endswith('.gpg'):
    ext = destfile[-4:]
    destfile = destfile[0:-4]
    if destfile[-4:] == '.gpg' and ext == '.asc':
      destfile = destfile[0:-4] + ext
    result = None
    if os.path.exists(destfile):
      os.remove(destfile)
    with open(filename, 'rb') as f:
      result = gpg.decrypt_file(f,
                                always_trust=True,
                                passphrase=config['encrypt-pw'],
                                output=destfile)
    if result is None:
      logging.error('Unable to decrypt (unknown reason): %s' % filename)
      return None
    if result is None or not os.path.exists(destfile):
      logging.error('Unable to decrypt (%s): %s' % (result.status, filename))
      return None
    filename = destfile

  if filename != destfile:
    fileutils.copy(filename, destfile)

  return destfile

def getBackupFiles(itemFromBackup):
  # Get the files in that folder and filter out the ones not part of the backup
  basename, ignore = os.path.basename(itemFromBackup).split('.', 1)
  basepath = os.path.dirname(itemFromBackup)
  if basepath == '':
    basepath = './'
  unfiltered = os.listdir(basepath)
  files = []
  for f in unfiltered:
    if os.path.basename(f).startswith(basename) or f == "filelist.txt":
      logging.debug('Found backup file "%s"' % f)
      files.append(f)
  return (basepath, files)



""" Parse command line """
parser = argparse.ArgumentParser(description="Iceshelf Restore - Restores the contents of an iceshelf backup", formatter_class=argparse.ArgumentDefaultsHelpFormatter)
parser.add_argument('--logfile', metavar="FILE", help="Log to file instead of stdout")
parser.add_argument('--debug', action='store_true', default=False, help='Adds more details to the log output')
parser.add_argument('--restore', metavar="DEST", default=None, help='Extracts the backup')
parser.add_argument('--list', action='store_true', default=False, help='List contents of backup (will not extract)')
parser.add_argument('--lastbackup', metavar='LAST', help='If set, requires the backup to be the successor of LAST')
parser.add_argument('--force', action='store_true', default=False, help='Even if manifest is missing, it will at least try to verify and repair archive')
parser.add_argument('config', metavar="CONFIG", help="Which config file to load")
parser.add_argument('backup', metavar="BACKUP", help="File from an iceshelf backup")
cmdline = parser.parse_args()

""" Setup logging first """
logging.getLogger('').handlers = []
loglevel=logging.INFO
if cmdline.logfile:
  logformat=u'%(asctime)s - %(levelname)s - %(message)s'
else:
  logformat=u'%(message)s'
if cmdline.debug:
  loglevel=logging.DEBUG
  logformat=u'%(asctime)s - %(filename)s@%(lineno)d - %(levelname)s - %(message)s'

logging.basicConfig(stream=sys.stdout, filename=cmdline.logfile, level=loglevel, format=logformat)
logging.getLogger("gnupg").setLevel(logging.WARNING)
logging.getLogger("shutil").setLevel(logging.WARNING)

# Make sure we have the correct gnupg module
if not "encrypt_file" in dir(gnupg.GPG()):
  logging.error("Current GnuPG python module does not support file encryption, please check FAQ section in documentation")
  sys.exit(255)

#######################

config = configuration.parse(cmdline.config, True)
if config is None:
  logging.error("Configuration is broken, please check %s" % cmdline.config)
  sys.exit(1)

if not os.path.isfile(cmdline.backup):
  logging.error('"%s" is not a file' % cmdline.backup.decode('UTF-8'))
  sys.exit(1)

basepath, files = getBackupFiles(cmdline.backup)

fileManifest = None
fileArchive = None

fileParity = None
filelist = None
oldfilelist = False
corruptFiles = []
processedFiles = []
skipParity = False

for f in files:
  if ".json" in f:
    fileManifest = f
  elif ".par2" in f:
    fileParity = f
  elif ".tar" in f:
    fileArchive = f
  elif f.endswith(".lst"):
    filelist = f
  elif f == "filelist.txt":
    oldfilelist = True

if fileManifest is None:
  if cmdline.force:
    logging.error("No manifest found, unable to restore. Will try to verify and repair if needed")
  else:
    logging.error("No manifest found, unable to restore (use --force to do as much as possible)")
    sys.exit(1)
if fileArchive is None:
  logging.error("No archive found, unable to continue")
  sys.exit(1)

if fileManifest is not None:
  logging.debug('Using manifest "%s"' % fileManifest)
if fileParity is not None:
  logging.debug("Parity is available")

# If we have a filelist, use it to confirm files
if filelist and not validArchive(basepath, filelist, corruptFiles, files) and not cmdline.force:
  sys.exit(1)
elif oldfilelist:
  logging.warn('Using older "filelist.txt" instead of new format using file ending in ".lst"')
  if not validArchive(basepath, "filelist.txt", corruptFiles, files) and not cmdline.force:
    sys.exit(1)


# Strip all files except archive (ie, verify signature and decrypt)
# since archive might need repairs and for that we need PAR2
for f in files:
  if f in corruptFiles:
    continue
  if f == fileArchive:
    continue
  if not validateFile(os.path.join(basepath, f)):
    logging.error('File "%s" signature does not match' % f)
    if not cmdline.force:
      sys.exit(1)

  # Do not extract files we don't need (ie, when not extracting)
  if not cmdline.list and not cmdline.restore:
    continue

  if f != fileManifest and not cmdline.restore:
    continue

  n = stripFile(os.path.join(basepath, f))
  if n is None:
    logging.error('Unable to process "%s"' % f)
    sys.exit(1)
  else:
    processedFiles.append(n)
    if n.endswith('.json'):
      fileManifest = n

if not cmdline.list and not cmdline.restore:
  sys.exit(0)

if cmdline.restore and fileParity is not None and len(corruptFiles) > 0:
  logging.info('Repairing corrupted archive file "%s"' % fileArchive)
  for f in processedFiles:
    if f.endswith(fileArchive + '.par2'):
      if not fileutils.repairParity(f):
        logging.error("Failed to repair file, not enough parity material")
        sys.exit(1)
      else:
        logging.info('File was repaired successfully')
      break

# Strip the archive
if cmdline.restore:
  if not validateFile(os.path.join(basepath, fileArchive)):
    logging.error('File "%s" signature does not match' % fileArchive)
    if not cmdline.force:
      sys.exit(1)
  archive = stripFile(os.path.join(basepath, fileArchive))
  if archive is None:
    logging.error('Unable to process "%s"' % fileArchive)
    sys.exit(1)
else:
    logging.info('No restore directory given. Exit.')
    sys.exit(0)

if fileManifest is None:
  logging.info('This is as much as can be done. You can now manually extract the files')
  sys.exit(0)

# And now... restore
manifest = None
with open(fileManifest) as fp:
  manifest = json.load(fp)

# If last backup is defined, check it
if cmdline.lastbackup is not None:
  if 'lastbackup' not in manifest:
    logging.debug('This backup does not specify a previous backup (made with an older version of iceshelf)')
  if 'lastbackup' not in manifest or manifest['lastbackup'] != cmdline.lastbackup:
    logging.error('Backup "%s" is not the successor of "%s"' % (os.path.basename(fileManifest)[0:-5], cmdline.lastbackup))
    sys.exit(1)

# If available, show which backup that preceeded it
if cmdline.list:
  if 'lastbackup' in manifest:
    logging.info('Manifest: Parent backup is "%s"' % manifest['lastbackup'])
  else:
    logging.debug('Manifest: Does not contain parent reference')

# Now, print the files we're changing or creating
filecount = 0
fileerror = 0
for k in manifest['modified']:
  v = manifest['modified'][k]
  src = os.path.normpath(cmdline.restore + k)
  if cmdline.list:
    logging.info('Manifest: Modified or new file "%s" in "%s"' % (os.path.basename(k), os.path.dirname(k)))
  filecount += 1

# Iterate the archive and make sure we know what's in it
if cmdline.restore:
  with tarfile.open(archive, "r:*") as tar:
    item = tar.next()
    while item != None:
      if '/' + item.name.decode('UTF-8') not in manifest['modified']:
        logging.error('Archive contains "%s", not listed in the manifest' % item.name.decode('UTF-8'))
        fileerror += 1
      else:
        manifest['modified']['/' + item.name.decode('UTF-8')]['found'] = True
        filecount -= 1
      item = tar.next()

  # Check that all files we were looking for was in the archive
  for k in manifest['modified']:
    if not 'found' in manifest['modified'][k]:
      logging.error('Archive is missing "%s"' % k)
      fileerror += 1

  if fileerror != 0 or filecount != 0:
    logging.error("Archive contains errors, aborting")
    sys.exit(1)

# Step 1: Remove any files that were deleted
for f in manifest['deleted']:
  src = os.path.normpath(cmdline.restore + f)
  if cmdline.list:
    logging.info('Manifest: Deleting "%s"' % src)
  if cmdline.restore:
    try:
      os.unlink(src);
    except:
      logging.warn('Unable to remove "%s"' % src)

for k in manifest['moved']:
  v = manifest['moved'][k]
  src = os.path.normpath(cmdline.restore + v['original'])
  dst = os.path.normpath(cmdline.restore + k)
  if cmdline.list:
    logging.info('Manifest: Moving "%s" to "%s"' % (src, dst))
  if cmdline.restore:
    try:
      os.rename(src, dst)
    except:
      logging.warn('Unable to move "%s" to "%s"' % (src, dst))

# Finally, if not a dryrun
if not cmdline.restore:
  sys.exit(0)

# Time to extract the files
with tarfile.open(archive, "r:*") as tar:
  item = tar.next()
  while item != None:
    filename = os.path.normpath(cmdline.restore + "/" + item.name.decode('UTF-8'))
    logging.info('Extracting "%s" to "%s"' % (os.path.basename(filename), os.path.dirname(filename)))
    tar.extract(item, cmdline.restore)
    item = tar.next()
logging.info("Backup has been restored")
